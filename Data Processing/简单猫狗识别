import os,random
import cv2
import numpy as np
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Dense, Flatten
from keras.utils import np_utils
import keras.losses as losses
from PIL import Image


# 1. 读取数据
def load_datas(dir_path):
    # 构建特征矩阵和目标向量
    datas = []
    y = []
    for image_name in os.listdir(dir_path):
        # 读取图片,构建特征矩阵
        datas.append(cv2.resize(cv2.imread(os.path.join(dir_path, image_name)), (227, 227)))
        # 构建目标向量
        if image_name.split('.')[0] == 'cat':
            y.append(1)
        else:
            y.append(0)
        # 对y进行独热(ont-hot)编码
    # y = np_utils.to_categorical(y)
    return np.array(datas), np.array(y)


def create_model(X, Y):
    # 1. 构建一个序列模型(空壳)
    # 卷积层：filters：卷积核个数，kernel_size卷积核大小，strides步长，padding补白
    # 池化层：pool_size过滤器大小，strides步长
    # 全连接层Dense：units神经元个数，activation激活函数
    model = Sequential()
    # 1. 卷积池化层
    # 卷积：96个卷积核，卷积核大小11 * 11 * 3，步长为4，补白为0
    model.add(Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4)))
    # 池化：最大池化层，过滤器的大小是3 * 3 ，步长为2
    model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))
    # 2. 卷积池化层
    #     卷积：256个卷积核，卷积核大小5 * 5 * 3，步长为1，补白为2
    model.add(Conv2D(filters=256, kernel_size=(5, 5), padding='same'))
    #     池化：最大池化层，过滤器大小3 * 3 ，步长为2
    model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))
    # 3. 卷积层
    #     卷积：384个卷积核，卷积核大小3 * 3 * 3 ，步长为1，补白为1
    model.add(Conv2D(filters=384, kernel_size=(3, 3)))
    # 4. 卷积层
    #     卷积：384个卷积核，卷积核大小3 * 3 * 3，步长为1，补白为1
    model.add(Conv2D(filters=384, kernel_size=(3, 3)))
    # 5. 卷积池化层
    #     卷积：256个卷积核，卷积核大小3 * 3 * 3，步长为1，补白为1
    model.add(Conv2D(filters=256, kernel_size=(3, 3)))
    #     池化：最大池化层，过滤器大小3 * 3，步长为2
    model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))
    # 6. 全连接层
    #     4096个神经元，激活函数ReLu
    model.add(Flatten())
    model.add(Dense(units=4096, activation='relu'))
    # 7. 全连接层
    #     4096个神经元，激活函数ReLu
    model.add(Dense(units=4096, activation='relu'))
    # 8. 全连接层
    #     2个神经元,激活函数使用sigmoid或者softmax
    model.add(Dense(units=2, activation='softmax'))
    # 对模型进行编译
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    model.fit(X, Y, epochs=10)
    return model


#3.预测
def m_predict(model):
    test_image= [cv2.resize(cv2.imread(os.path.join(r'E:/Download/test3/', r'2.jpg')), (227, 227))]
    #test_image = cv2.resize(cv2.imread(r'E:\Download\train\cat.113.jpg'), (224, 224))
    #test_image = np.asarray(test_image.astype(float))
    test_image = np.array(test_image) / 255
    # test_image = test_image.reshape((1,224, 224, 3))
    preds = model.predict(test_image)
    # print(preds)
    if preds.argmax() == 0:
        print("cat")
    else:
        print("dog")

if __name__ == '__main__':
    dir_path = r'E:\Download\train3'
    X, Y = load_datas(dir_path)
    X = X / 255
    m = create_model(X, Y)
    m_predict(m)




